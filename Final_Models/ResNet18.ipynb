{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2680f7-867d-467a-83ca-7f8cc7488345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel                      as nib\n",
    "import nibabel.freesurfer.mghformat as mgh\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d334c94-983f-4684-808d-9367113c60a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices())\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa10257-88a1-413f-9ee6-0cb7ca835982",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "def read_mgz_file(filepath):\n",
    "    \"\"\"Read and load volume\"\"\"\n",
    "    # Read file\n",
    "    scan = mgh.load(filepath)\n",
    "    # Get raw data\n",
    "    scan = scan.get_fdata()\n",
    "    return scan\n",
    "\n",
    "def convertersize(volume):\n",
    "    \"\"\"convertersize the volume\"\"\"\n",
    "    min = -1000\n",
    "    max = 400\n",
    "    volume[volume < min] = min\n",
    "    volume[volume > max] = max\n",
    "    volume = (volume - min) / (max - min)\n",
    "    volume = volume.astype(\"float32\")\n",
    "    return volume\n",
    "\n",
    "def resize_volume(img):\n",
    "    \"\"\"Resize across z-axis\"\"\"\n",
    "    # Set the desired depth\n",
    "    desired_depth = 256\n",
    "    desired_width = 256\n",
    "    desired_height = 256\n",
    "    # Get current depth\n",
    "    current_depth = img.shape[-1]\n",
    "    current_width = img.shape[0]\n",
    "    current_height = img.shape[1]\n",
    "    # Compute depth factor\n",
    "    depth = current_depth / desired_depth\n",
    "    width = current_width / desired_width\n",
    "    height = current_height / desired_height\n",
    "    depth_factor = 1 / depth\n",
    "    width_factor = 1 / width\n",
    "    height_factor = 1 / height\n",
    "    # Rotate\n",
    "    img = ndimage.rotate(img, 270, reshape=False)\n",
    "    # Resize across z-axis\n",
    "    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n",
    "    return img\n",
    "\n",
    "def crop_image(img):\n",
    "    # Find first and last slices that contain parts of the brain\n",
    "    blank = img[0].sum()\n",
    "    x = []\n",
    "    for i in range(len(img)):\n",
    "        if img[i,:,:].sum() != blank:\n",
    "            x.append(i)\n",
    "    y = []\n",
    "    for i in range(len(img)):\n",
    "        if img[:,i,:].sum() != blank:\n",
    "            y.append(i)\n",
    "    z = []\n",
    "    for i in range(len(img)):\n",
    "        if img[:,:,i].sum() != blank:\n",
    "            z.append(i)\n",
    "    # Use these to crop the 3D images\n",
    "    img = np.squeeze(img[min(x):max(x), min(y):max(y), min(z):max(z)])\n",
    "    \n",
    "    # Set the desired depth\n",
    "    desired_depth = 128\n",
    "    desired_width = 128\n",
    "    desired_height = 128\n",
    "    # Get current depth\n",
    "    current_depth = img.shape[-1]\n",
    "    current_width = img.shape[0]\n",
    "    current_height = img.shape[1]\n",
    "    # Compute depth factor\n",
    "    depth = current_depth / desired_depth\n",
    "    width = current_width / desired_width\n",
    "    height = current_height / desired_height\n",
    "    depth_factor = 1 / depth\n",
    "    width_factor = 1 / width\n",
    "    height_factor = 1 / height\n",
    "    # Resize across z-axis\n",
    "    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n",
    "    return img\n",
    "\n",
    "def create_patches(img):\n",
    "    patches=[]\n",
    "    for i in [0,32,64]:\n",
    "        for j in [0,32,64]:\n",
    "            for k in [0,32,64]:\n",
    "                patch = np.squeeze(img[i:(i+64), j:(j+64), k:(k+64)])\n",
    "                # [0, 1] normalization\n",
    "                patch = patch/(patch.max()/1)\n",
    "                patch = patch - 1\n",
    "                patch = abs(patch)\n",
    "                patch = patch/(patch.max()/1)\n",
    "                patch = abs(patch-1)\n",
    "                patches.append(patch)\n",
    "    return patches\n",
    "\n",
    "def process_scan(path):\n",
    "    \"\"\"Read and resize volume\"\"\"\n",
    "    # Read scan\n",
    "    volume = read_mgz_file(path)\n",
    "    #  convertersize\n",
    "    volume = convertersize(volume)\n",
    "    # Resize width, height and depth\n",
    "    volume = resize_volume(volume)\n",
    "    # Crop 3D image\n",
    "    volume = crop_image(volume)\n",
    "    # Create patches\n",
    "    volume = create_patches(volume)\n",
    "    return volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c47bc60-ffe3-419c-afe5-6a69c1d554f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = process_scan('Train_CN/OAS30015_MR_d0116.mgz')\n",
    "fig = plt.figure(figsize=(21, 7))\n",
    "columns = 9\n",
    "rows = 3\n",
    "for i in range(1, columns*rows +1):\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(np.squeeze(patches[i-1][:, :, 32]), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e92ef83-79fd-4ff1-b04d-49271b12083f",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1142fb3a-824f-441a-8412-1c020941373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder \"Train_CN\" consist of subjects who remained cognitively converters for the whole study.\n",
    "Train_CN_paths = [\n",
    "    os.path.join(os.getcwd(), \"Train_CN\", x)\n",
    "    for x in os.listdir(\"Train_CN\")\n",
    "]\n",
    "\n",
    "# Folder \"Val_CN\" consist of subjects who remained cognitively converters for the whole study.\n",
    "Val_CN_paths = [\n",
    "    os.path.join(os.getcwd(), \"Val_CN\", x)\n",
    "    for x in os.listdir(\"Val_CN\")\n",
    "]\n",
    "\n",
    "# Folder \"Test_CN\" consist of subjects who remained cognitively converters for the whole study.\n",
    "Test_CN_paths = [\n",
    "    os.path.join(os.getcwd(), \"Test_CN\", x)\n",
    "    for x in os.listdir(\"Test_CN\")\n",
    "]\n",
    "\n",
    "\n",
    "# Folder \"Train_Converters\" consist of subjects who converted from CN to MCI > 0.\n",
    "Train_Converters_paths = [\n",
    "    os.path.join(os.getcwd(), \"Train_Converters\", x)\n",
    "    for x in os.listdir(\"Train_Converters\")\n",
    "]\n",
    "\n",
    "# Folder \"Val_Converters\" consist of subjects who converted from CN to MCI > 0.\n",
    "Val_Converters_paths = [\n",
    "    os.path.join(os.getcwd(), \"Val_Converters\", x)\n",
    "    for x in os.listdir(\"Val_Converters\")\n",
    "]\n",
    "\n",
    "# Folder \"Test_Converters\" consist of subjects who converted from CN to MCI > 0.\n",
    "Test_Converters_paths = [\n",
    "    os.path.join(os.getcwd(), \"Test_Converters\", x)\n",
    "    for x in os.listdir(\"Test_Converters\")\n",
    "]\n",
    "\n",
    "print(\"MRI scans for patients remaining CN (Train): \" + str(len(Train_CN_paths)))\n",
    "print(\"MRI scans for patients remaining CN (Val): \" + str(len(Val_CN_paths)))\n",
    "print(\"MRI scans for patients remaining CN (Test): \" + str(len(Test_CN_paths)))\n",
    "\n",
    "print(\"MRI scans for patients converting to AD (Train): \" + str(len(Train_Converters_paths)))\n",
    "print(\"MRI scans for patients converting to AD (Val): \" + str(len(Val_Converters_paths)))\n",
    "print(\"MRI scans for patients converting to AD (Test): \" + str(len(Test_Converters_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fce375a-759e-4fcb-927e-6fe8af643b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and process the scans.\n",
    "# Each scan is resized across height, width, and depth and rescaled.\n",
    "Train_CN_scans = np.array([process_scan(path) for path in Train_CN_paths])\n",
    "Val_CN_scans = np.array([process_scan(path) for path in Val_CN_paths])\n",
    "Test_CN_scans = np.array([process_scan(path) for path in Test_CN_paths])\n",
    "\n",
    "Train_Converters_scans = np.array([process_scan(path) for path in Train_Converters_paths])\n",
    "Val_Converters_scans = np.array([process_scan(path) for path in Val_Converters_paths])\n",
    "Test_Converters_scans = np.array([process_scan(path) for path in Test_Converters_paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7786891a-94bc-43b6-8973-5eabbfe01dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the converters assign 1, for the CN subjects assign 0.\n",
    "Train_CN_labels = np.array([0 for _ in range(len(Train_CN_scans))])\n",
    "Val_CN_labels = np.array([0 for _ in range(len(Val_CN_scans))])\n",
    "Test_CN_labels = np.array([0 for _ in range(len(Test_CN_scans))])\n",
    "\n",
    "Train_Converters_labels = np.array([1 for _ in range(len(Train_Converters_scans))])\n",
    "Val_Converters_labels = np.array([1 for _ in range(len(Val_Converters_scans))])\n",
    "Test_Converters_labels = np.array([1 for _ in range(len(Test_Converters_scans))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2698afd-15ec-4ab2-af53-2ba1e17f16f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(27): # For all 27 of the patches\n",
    "    # Read the patches from the processed scans.\n",
    "    Train_CN_patches = np.array([scan[i,:,:,:] for scan in Train_CN_scans])\n",
    "    Val_CN_patches = np.array([scan[i,:,:,:] for scan in Val_CN_scans])\n",
    "    Test_CN_patches = np.array([scan[i,:,:,:] for scan in Test_CN_scans])\n",
    "    Train_Converters_patches = np.array([scan[i,:,:,:] for scan in Train_Converters_scans])\n",
    "    Val_Converters_patches = np.array([scan[i,:,:,:] for scan in Val_Converters_scans])\n",
    "    Test_Converters_patches = np.array([scan[i,:,:,:] for scan in Test_Converters_scans])\n",
    "\n",
    "    # Create x and y values for train, validation and test sets\n",
    "    x_train = np.concatenate((Train_CN_patches, Train_Converters_patches), axis=0)\n",
    "    x_val = np.concatenate((Val_CN_patches, Val_Converters_patches), axis=0)\n",
    "    x_test = np.concatenate((Test_CN_patches, Test_Converters_patches), axis=0)\n",
    "    y_train = np.concatenate((Train_CN_labels, Train_Converters_labels), axis=0)\n",
    "    y_val = np.concatenate((Val_CN_labels, Val_Converters_labels), axis=0)\n",
    "    y_test = np.concatenate((Test_CN_labels, Test_Converters_labels), axis=0)\n",
    "\n",
    "    # Convert image data to RGB (3 channels) so ImageNet weights work\n",
    "    x_train_rgb = np.repeat(x_train[..., np.newaxis], 3, -1)\n",
    "    x_val_rgb = np.repeat(x_val[..., np.newaxis], 3, -1)\n",
    "    x_test_rgb = np.repeat(x_test[..., np.newaxis], 3, -1)\n",
    "\n",
    "    # Define data loaders.\n",
    "    train_loader = tf.data.Dataset.from_tensor_slices((x_train_rgb, y_train))\n",
    "    validation_loader = tf.data.Dataset.from_tensor_slices((x_val_rgb, y_val))\n",
    "    test_loader = tf.data.Dataset.from_tensor_slices((x_test_rgb, y_test))\n",
    "\n",
    "    batch_size = 20\n",
    "    train_dataset = (\n",
    "        train_loader.shuffle(len(x_train_rgb))\n",
    "        .batch(batch_size)\n",
    "        .prefetch(1)\n",
    "    )\n",
    "    validation_dataset = (\n",
    "        validation_loader.shuffle(len(x_val_rgb))\n",
    "        .batch(batch_size)\n",
    "        .prefetch(1)\n",
    "    )\n",
    "    test_dataset = (\n",
    "        validation_loader.shuffle(len(x_test_rgb))\n",
    "        .batch(batch_size)\n",
    "        .prefetch(1)\n",
    "    )\n",
    "\n",
    "    # for tensorflow.keras\n",
    "    from classification_models_3D.tfkeras import Classifiers\n",
    "\n",
    "    ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
    "    base_model = ResNet18(input_shape=(64, 64, 64, 3), weights='imagenet')\n",
    "\n",
    "    x = base_model.output\n",
    "    x = tf.keras.layers.Dense(1000,activation='relu')(x) \n",
    "    x = tf.keras.layers.Dense(500,activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(200,activation='relu')(x) \n",
    "    x = tf.keras.layers.Dense(1, activation= 'sigmoid')(x)\n",
    "    model = keras.Model(inputs = base_model.input, outputs = x)\n",
    "\n",
    "    auc = tf.keras.metrics.AUC()  # instantiate it here to have a shorter handle\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        metrics=[\"acc\", auc],\n",
    "    )\n",
    "\n",
    "    # Define callbacks.\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "        str(\"ResNet18/3d_image_classification\"+str(i)+\".h5\"), save_best_only=True\n",
    "    )\n",
    "    early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_acc\", patience=100)\n",
    "\n",
    "    # Train the model, doing validation at the end of each epoch\n",
    "    epochs = 1000\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=validation_dataset,\n",
    "        epochs=epochs,\n",
    "        shuffle=True,\n",
    "        verbose=2,\n",
    "        callbacks=[checkpoint_cb, early_stopping_cb],\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 3))\n",
    "    ax = ax.ravel()\n",
    "\n",
    "    for i, metric in enumerate([\"acc\", \"loss\"]):\n",
    "        ax[i].plot(model.history.history[metric])\n",
    "        ax[i].plot(model.history.history[\"val_\" + metric])\n",
    "        ax[i].set_title(\"Model {}\".format(metric))\n",
    "        ax[i].set_xlabel(\"epochs\")\n",
    "        ax[i].set_ylabel(metric)\n",
    "        ax[i].legend([\"train\", \"val\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
